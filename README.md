Hereâ€™s how it fits together for your MVP:
Evaluation Pipeline (MVP-Friendly)
Topic extraction
From current session transcript â†’ extract main subject + subtopics.
From previous session transcript â†’ extract main subject + subtopics.
Score recall
Pull the previous quiz score (overall percentage).
Note which topics the quiz was based on.
Progress evaluation
Compare topics overlap (continuity vs. new material).
Reference previous quiz score:
If score was high â†’ say â€œunderstanding was reinforced through the quizâ€ and that todayâ€™s topics built upon it.
If score was low â†’ say â€œsome gaps identified in the quiz can be addressed alongside todayâ€™s topics.â€
Quiz/question generation (progression-aware)
Based on todayâ€™s subtopics.
Bias the difficulty slightly depending on last score (higher score â†’ harder questions, lower score â†’ reinforcement of basics).
What should you target in evaluation?
Keep it simple and session-focused:
âœ… Mention what was covered previously (topics + quiz performance).
âœ… Mention what was covered now (topics).
âœ… Connect them: did the new session build upon, reinforce, or diverge from the previous one?
âœ… Give a short progress note (e.g., â€œstronger understanding of algebra compared to last weekâ€ or â€œgeometry basics introduced after reviewing algebra foundationsâ€).
System prompt strategy
Donâ€™t compare the whole transcript â†’ thatâ€™s too noisy.
Instead, compare topics + quiz score + teacherâ€™s notes (optional).
You can pass in a structured summary like:
{
  "previous_topics": ["Linear Equations", "Fractions"],
  "previous_score": "72%",
  "current_topics": ["Quadratic Equations", "Factorization"],
  "current_transcript": "..."
}
Then let the LLM generate:
Evaluation summary (progress, reinforcement, gaps).
Quiz (3â€“5 questions).
ğŸ‘‰ This way, the score isnâ€™t mandatory every time, but when itâ€™s there, it grounds the evaluation in measurable progress.
Do you want me to draft a sample evaluation output that ties together previous topics + quiz score + current topics so you can see how it looks in practice?



